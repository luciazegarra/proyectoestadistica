# -*- coding: utf-8 -*-
"""
PredicciÃ³n de SatisfacciÃ³n de Vida con diferentes modelos
"""

import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# ConfiguraciÃ³n de pÃ¡gina
st.set_page_config(page_title="PredicciÃ³n de SatisfacciÃ³n de Vida", layout="wide")

# TÃ­tulo principal
st.title("ğŸ” PredicciÃ³n de SatisfacciÃ³n de Vida")

# Cargar datos
@st.cache_data
def cargar_datos():
    return pd.read_csv("dataset_estadistica.csv")

ds = cargar_datos()

# Mostrar columnas
st.write("ğŸ“‹ Columnas del dataset:", ds.columns.tolist())

# Vista previa
st.subheader("ğŸ“Œ Vista previa de los datos")
st.dataframe(ds.head())

# EstadÃ­stica descriptiva
st.subheader("ğŸ“Š EstadÃ­stica Descriptiva de Variables NumÃ©ricas")
st.dataframe(ds.describe())

# Variables numÃ©ricas
ds_num = ds.select_dtypes(include='number')

# Pairplot
st.subheader("ğŸ“Š Relaciones entre variables numÃ©ricas (Pairplot)")
fig1 = sns.pairplot(ds_num)
st.pyplot(fig1)

# Matriz de correlaciÃ³n
st.subheader("ğŸ“ˆ Matriz de correlaciÃ³n")
fig2, ax2 = plt.subplots(figsize=(6, 4))
sns.heatmap(ds_num.corr(), annot=True, cmap="coolwarm", ax=ax2)
st.pyplot(fig2)

# Histogramas + KDE
st.subheader("ğŸ“‰ Distribuciones de variables numÃ©ricas")
for columna in ds_num.columns:
    fig, ax = plt.subplots()
    sns.histplot(ds[columna], kde=True, ax=ax, color='skyblue')
    ax.set_title(f"DistribuciÃ³n de {columna}")
    st.pyplot(fig)

# Boxplots
st.subheader("ğŸ“¦ Boxplots de variables numÃ©ricas")
for columna in ds_num.columns:
    fig, ax = plt.subplots()
    sns.boxplot(x=ds[columna], ax=ax, color='lightgreen')
    ax.set_title(f"Boxplot de {columna}")
    st.pyplot(fig)

# ValidaciÃ³n de columnas
columnas_requeridas = ['Edad', 'Ingreso_Mensual', 'Horas_Estudio_Semanal', 'Satisfaccion_Vida']
if all(col in ds.columns for col in columnas_requeridas):

    # SelecciÃ³n de variables
    X = ds[['Edad', 'Ingreso_Mensual', 'Horas_Estudio_Semanal']]
    y = ds['Satisfaccion_Vida']

    # Limpieza
    df_limpio = pd.concat([X, y], axis=1)
    df_limpio.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_limpio.dropna(inplace=True)

    X = df_limpio[['Edad', 'Ingreso_Mensual', 'Horas_Estudio_Semanal']]
    y = df_limpio['Satisfaccion_Vida']

    # DivisiÃ³n de datos
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Sidebar: SelecciÃ³n de modelo
    st.sidebar.header("1ï¸âƒ£ Selecciona el modelo de predicciÃ³n")
    modelo_seleccionado = st.sidebar.selectbox("Modelo", ["RegresiÃ³n Lineal", "Ãrbol de DecisiÃ³n", "KNN"])

    # NormalizaciÃ³n solo para KNN
    if modelo_seleccionado == "KNN":
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)
        normalizador_aplicado = True
    else:
        normalizador_aplicado = False

    # Crear modelo
    if modelo_seleccionado == "RegresiÃ³n Lineal":
        modelo = LinearRegression()
    elif modelo_seleccionado == "Ãrbol de DecisiÃ³n":
        modelo = DecisionTreeRegressor()
    elif modelo_seleccionado == "KNN":
        modelo = KNeighborsRegressor(n_neighbors=5)

    # Entrenamiento
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)

    # Resultados
    st.subheader("ğŸ“‹ EvaluaciÃ³n del modelo")
    st.write(f"ğŸ”§ Modelo seleccionado: **{modelo_seleccionado}**")
    if normalizador_aplicado:
        st.info("âš™ï¸ Se aplicÃ³ normalizaciÃ³n estÃ¡ndar porque se eligiÃ³ KNN.")
    st.write("âœ… Error CuadrÃ¡tico Medio (MSE):", round(mean_squared_error(y_test, y_pred), 2))
    st.write("âœ… Coeficiente de DeterminaciÃ³n (RÂ²):", round(r2_score(y_test, y_pred), 2))

    # GrÃ¡fico de comparaciÃ³n
    st.subheader("ğŸ“Œ ComparaciÃ³n: Valor real vs predicho")
    fig3, ax3 = plt.subplots()
    ax3.scatter(y_test, y_pred, alpha=0.6)
    ax3.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    ax3.set_xlabel("Real")
    ax3.set_ylabel("Predicho")
    ax3.set_title("ComparaciÃ³n Real vs PredicciÃ³n")
    st.pyplot(fig3)

    # Formulario individual
    st.sidebar.header("2ï¸âƒ£ Predecir nueva satisfacciÃ³n de vida")
    Edad = st.sidebar.slider("Edad", 18, 80, 30)
    Ingreso = st.sidebar.slider("Ingreso Mensual (Bs)", 0, 10000, 3000)
    Hrs_Estudio = st.sidebar.slider("Horas de estudio semanales", 0, 40, 10)

    if st.sidebar.button("ğŸ”® Predecir"):
        entrada = np.array([[Edad, Ingreso, Hrs_Estudio]])
        if normalizador_aplicado:
            entrada = scaler.transform(entrada)
        pred_nueva = modelo.predict(entrada)
        st.sidebar.success(f"Nivel de satisfacciÃ³n estimado: {pred_nueva[0]:.2f}")

else:
    st.error("âŒ Las columnas necesarias no existen en el dataset. Revisa que tengas: 'Edad', 'Ingreso_Mensual', 'Horas_Estudio_Semanal', 'Satisfaccion_Vida'")
